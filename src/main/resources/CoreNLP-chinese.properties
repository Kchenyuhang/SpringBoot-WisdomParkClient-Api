# Pipeline options - lemma is no-op for Chinese but currently needed because coref demands it (bad old requirements system)
#设定了管道中包括哪些Annotators（一个Annotator就是你需要的文本分析分析工具， 他的结果就是一个或多个Annotation）
#segment:分词, ssplit:分隔, pos: 词性标注, lemma: has->have, ner:命名实体识别, parse：语法分析
#annotators = segment, ssplit, pos, lemma, ner, parse, sentiment, mention, coref
#annotators = segment, ssplit, pos, parse, sentiment
annotators=segment, tokenize, ssplit
# segment 分词
customAnnotatorClass.segment=edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator
segment.model=edu/stanford/nlp/models/segmenter/chinese/pku.gz
segment.sighanCorporaDict=edu/stanford/nlp/models/segmenter/chinese
segment.serDictionary=edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz
segment.sighanPostProcessing=true
# sentence split
ssplit.boundaryTokenRegex=[.]|[!?]+|[\u3002]|[\uFF01\uFF1F]+
#ssplit.boundaryTokenRegex = [.。；;]|[!?！？]+
# pos
pos.model=edu/stanford/nlp/models/pos-tagger/chinese-distsim/chinese-distsim.tagger
#ner 此处设定了ner使用的语言、模型（crf），目前SUTime只支持英文，不支持中文，所以设置为false。
ner.language=chinese
ner.model=edu/stanford/nlp/models/ner/chinese.misc.distsim.crf.ser.gz
ner.applyNumericClassifiers=true
ner.useSUTime=false
#parse
parse.model=edu/stanford/nlp/models/lexparser/chineseFactored.ser.gz
# coref
coref.sieves=ChineseHeadMatch, ExactStringMatch, PreciseConstructs, StrictHeadMatch1, StrictHeadMatch2, StrictHeadMatch3, StrictHeadMatch4, PronounMatch
coref.input.type=raw
coref.postprocessing=true
coref.calculateFeatureImportance=false
coref.useConstituencyTree=true
coref.useSemantics=false
coref.md.type=RULE
coref.mode=hybrid
coref.path.word2vec=
coref.language=zh
coref.print.md.log=false
coref.defaultPronounAgreement=true
coref.zh.dict=edu/stanford/nlp/models/dcoref/zh-attributes.txt.gz